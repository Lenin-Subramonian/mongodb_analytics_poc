# docker-compose.yml - Multi-service orchestration
# version: '3.8'

services:
  # Main ETL Application
  mongodb-etl:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: mongodb-iceberg-etl
    environment:
      # Load from .env file
      - MONGODB_ATLAS_USERNAME=${MONGODB_ATLAS_USERNAME}
      - MONGODB_ATLAS_PASSWORD=${MONGODB_ATLAS_PASSWORD}
      - MONGODB_ATLAS_CLUSTER=${MONGODB_ATLAS_CLUSTER}
      - MONGODB_DATABASE=${MONGODB_DATABASE}
      - MONGODB_COLLECTION=${MONGODB_COLLECTION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION:-us-east-2}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION:-${AWS_REGION:-us-east-2}}
      - S3_BUCKET=${S3_BUCKET}
      - GLUE_CATALOG_NAME=${GLUE_CATALOG_NAME:-iceberg}
      - LOG_LEVEL=${LOG_LEVEL}
      - BATCH_SIZE=${BATCH_SIZE}
      # Iceberg / packages settings (change versions here without rebuilding)
      # - PACKAGES=${PACKAGES:-org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.hadoop:hadoop-aws:3.3.6,com.amazonaws:aws-java-sdk-bundle:1.12.540,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0}
      - PACKAGES=${PACKAGES:-org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.hadoop:hadoop-aws:3.3.6,software.amazon.awssdk:glue:2.20.137,software.amazon.awssdk:s3:2.20.137,software.amazon.awssdk:sts:2.20.137,software.amazon.awssdk:dynamodb:2.20.137,software.amazon.awssdk:kms:2.20.137,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0}
      - WAREHOUSE=s3a://${S3_BUCKET:-fq-app-analytics-bucket-1}/iceberg-warehouse/
      # s3://fq-app-analytics-bucket-1/iceberg-warehouse/fq_app_db_raw/
      # Optional: increase Spark driver/executor mem via env if needed
      - SPARK_DRIVER_MEMORY=${SPARK_DRIVER_MEMORY:-1g}
      - SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY:-1g}
    volumes:
      # Mount source code for development
      - ./src:/app/src:ro
      - ./scripts:/app/scripts:ro
      - ./config:/app/config:ro
      # Mount data and logs directories
      - ./data:/app/data
      - ./logs:/app/logs
      # Mount notebooks for Jupyter
      - ./notebooks:/app/notebooks
      # Cache Maven / Ivy artifacts between runs to avoid re-downloading
      # USE named docker volumes (not host binds) to avoid Windows permission problems:
      - ivy2-cache:/home/spark/.ivy2
      - m2-cache:/home/spark/.m2
    ports:
      - "4040:4040"  # Spark UI
      - "4041:4041"  # Spark History Server
    networks:
      - analytics-network
    healthcheck:
      test: ["CMD", "python3", "-c", "import pyspark; print('OK')"]
      interval: 30s
      timeout: 10s
      retries: 3
    entrypoint: ["/entrypoint.sh"]

  # Jupyter Lab for Interactive Analysis
  jupyter:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: mongodb-analytics-jupyter
    command: >
      bash -c "mkdir -p /home/spark/.jupyter /home/spark/.local && 
      chown -R spark:spark /home/spark && 
      jupyter lab 
      --ip=0.0.0.0 
      --port=8888 
      --no-browser 
      --allow-root 
      --NotebookApp.token=${JUPYTER_TOKEN:-analytics123} 
      --NotebookApp.notebook_dir=/app/notebooks"   
    
    user: root
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-analytics123}
      - JUPYTER_CONFIG_DIR=/app/.jupyter
      # Mirror PACKAGES into Jupyter if you'd like interactive sessions to auto-fetch same connectors
      # - PACKAGES=${PACKAGES:-org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.hadoop:hadoop-aws:3.3.6,com.amazonaws:aws-java-sdk-bundle:1.12.540,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0}
      - PACKAGES=${PACKAGES:-org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.2,org.apache.hadoop:hadoop-aws:3.3.6,software.amazon.awssdk:glue:2.20.137,software.amazon.awssdk:s3:2.20.137,software.amazon.awssdk:sts:2.20.137,software.amazon.awssdk:dynamodb:2.20.137,software.amazon.awssdk:kms:2.20.137,org.mongodb.spark:mongo-spark-connector_2.12:10.3.0}
      - WAREHOUSE=s3a://${S3_BUCKET:-fq-app-analytics-bucket-1}/iceberg-warehouse/
    volumes:
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ivy2-cache:/home/spark/.ivy2
      - m2-cache:/home/spark/.m2
    ports:
      - "8888:8888"  # Jupyter Lab
    networks:
      - analytics-network
    depends_on:
      - mongodb-etl
    restart: unless-stopped

volumes:
  ivy2-cache:
  m2-cache:
  mongodb_data:
    driver: local

networks:
  analytics-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16